# data-engineering-greatExpectations
 A demo for Data Engineer for using Great Expectations

---

## Language
* For programming language, this repo use `Python`
* For structured query language, this repo use `PostgreSQL`
* For manage data container, this repo use `Docker`
---

## Data Platform
* Docker
* Airflow
* GreatExpectations
* PostgreSQL
---

## Application
* Visual Studio Code (VSCode)
* DBeaver
* Docker Desktop
---

## Credentials
* Airflow (http://localhost:8080)
	* User: airflow
	* Password: airflow

* PostgreSQL (localhost:5432)
	* Database: postgres 
	* Schema: postgres
	* User: postgres
	* Password: KantorAHP123!
---
## PostgreSQL Setup
1. Make a PostgreSQL connection on `DBeaver` called `postgres` and the credentials refers to [`**Credentials**`]()
2. 


---

## Additional Resources
This repo has several reference sources for working on it:
* [Demo data pipeline with dbt, Airflow, Great Expectations](https://github.com/spbail/dag-stack)
* [Building A Robust Data Pipeline With Great Expectations, dbt and Airflow](https://medium.com/@Sasakky/building-a-robust-data-pipeline-with-great-expectations-dbt-and-airflow-d12b8bba030)
* [Simple data pipeline](https://github.com/goFrendiAsgard/platform-data)
